# api server parameters:
server:
    # api key to get access to the server
    api_key_prompt_server: ""

    # server address
    api_prompt_server_url: "http://35.222.204.141:9100/submit"

    # maximum amount of retries accessing the server before continue prompt generation
    server_max_retries_number: 5

    # wait time in seconds before reattempting to send the data to the server
    server_retry_delay: 1

# parameters for running Groq API
groq_api:
    # put here token generated at https://console.groq.com/keys
    api_key: ""

    # one of the models supported by groq platform: llama3-70b-8192, mixtral-8x7b-32768, gemma-7b-it
    llm_model: "llama3-8b-8192"

    # llm model for checking prompts
    llm_model_prompt_checker: "gemma-7b-it"

    # max tokens for prompt generation
    max_tokens: 256

    # random seed
    seed: -1

# parameters for running vLLM api
vllm_api:
    # the vllm model that will be used for the prompt generation
    # awq - quantization level of the model supported by the vllm
    llm_model: "casperhansen/llama-3-8b-instruct-awq"

    # the llm model that will be used for checking the quality of the prompts
    llm_model_prompt_checker: "TechxGenus/gemma-1.1-7b-it-AWQ"

    # max tokens for prompt generation
    max_tokens: 256

    # random seed
    seed: 0

transformers_llm_model_prompt_checker: "google/gemma-1.1-7b-it"

# hugging face api token, can be generated within your account on the platform. Will be required
# for downloading gemma LLM.
hugging_face_api_key: ""

# the prompt that will be used for generating the dataset.
# NOTE: member_placeholder and prompts_num are mandatory placeholders.
# prompts_num will be replaced with prompts_num from this config;
# member_placeholder will be replaced with one of the strings stored in obj_categories list.

prompt: "Generate a prompt dataset for generating 3D models.
         Each prompt should define a single 3D object that can be generated as a 3D mesh.
         The prompt should contain one or two distinctive features such as color, shape, or pose of the generating object.  
         Each object should be different and must be strictly picked from the member_placeholder category.
         Each prompt should be unique, on the new line, consists of between three to ten words.
         Generate a numbered list of prompts_num prompts.
        "

# Categories of objects from where the LLM model could sample the data.
obj_categories: ["humanoids", "animals", "monsters", "robots", "buildings", "nature", "vehicles", "weapons and equipments",
                 "food and drinks", "gadgets and electronics", "decorative elements", "furniture", "jewelry"]

# Words that prompts should npt contain. Prompts with these words will be removed from the dataset and filtering stage.
filter_prompts_with_words: ["sky", "skies", "river", "ocean", "sea", "garden", "wind", "field", "terrain", "family", "tow", "city", "accessories",
                            "jungle", "forest", "space", "pool", "pond", "I", "i", "fields", "horizon", "oops", "hillside", "underwater",
                            "floor", "grass", "nature", "mist", "air", "waterfall", "music", "sunset", "sunrise", "beach", "room", "cluster", "accents",
                            "melody", "wind", "winds", "tale", "sure", "prompts", "prompt", "sunbeam", "water", "word", "words", "money", "copy",
                            "vacuum", "outdoor", "to", "us", "miami", "kidding", "time", "sunken", "point", "like", "breathing", "whoops", "labyrinth",
                            "village", "seaside", "cloud", "clouds", "exterior", "no", "unit", "harbor", "window", "grip", "island", "song", "ambiance",
                            "orbit", "hope", "melody", "animate", "vagina"]

# amount of prompts to generate per category.
prompts_num: 30

# specify number of times you want to run the model (total prompt size: prompts_num x len(obj_categories) x iteration_num
# if set to -1, the prompts will be generated infinitely
iteration_num: -1

# file where to output the prompts (.txt file)
prompts_output_file: "prompt_dataset.txt"
